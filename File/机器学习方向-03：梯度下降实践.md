![](image/ml.png)

# 机器学习方向-03：梯度下降实践

> `难度系数`：简单
>
> 看了那么多理论，不妨来试试实战吧！高中的时候都学过用最小二乘法求直线方程，你知道它是怎么来的吗？不用怕，这里不用你推导它。根据采样点求直线可以直接套公式就好了，可惜更多时候这个公式**复杂得超乎想象甚至根本不存在**，这时候就该我们登场了。上吧，梯度下降法！
>
> **温馨提示：这道题比上一道简单😊**


## 题目要求

- 生成数据集,随机生成常数 $$a,b,c$$。
生成 500 条数据，满足以下条件： 
$$\begin{cases}
F(x,y)=ax^2+by+c+e\\
x\sim U(-2, 2)\\
y\sim U(-5, 5)\\
e\sim N(0, 0.01)
\end{cases}$$
其中，$$x\sim U(-2,2)$$表示随机变量 $$x$$ 服从 $$-2$$ 到 $$2$$的均匀分布，$$e$$为人为构造的噪声，$$e\sim N(0,0.01)$$ 表示随机变量 $$e$$ 服从均值为 $$0$$，方差为 $$0.01$$ 的正态分布。
- 应用**梯度下降法**，求出恰当的 $$\hat{a}, \hat{b}, \hat{c}$$ ，使每个数据点到平面 $$\hat{F}(x,y)=\hat{a}x^2+\hat{b}y+\hat{c}$$ 的**竖直方向距离（Z轴方向）的平方之和**最小。 训练过程中，要求每 20 次迭代打印当前损失（点到平面的竖直距离）。
- 将上述任务代入到机器学习中，$$F(x, y)$$即标签label，而$$\hat{F}(x, y)$$即每次的预测值，损失采用了MSE损失
- 如果你正确的使用了梯度下降法，那么求得的 $$\hat{a},\hat{b},\hat{c}$$ 将与你预先设定的 $$a,b,c$$ 非常接近。

## 回答要求

1. 生成数据的代码 和 拟合数据的代码；
2. 代码运行结果截图；
3. 必要的注释说明及良好的代码规范；
4. 实现思路和学到的知识点。

## 需要掌握的知识点

1. 梯度下降法的原理
2. 基础的Python语法（***库函数只能使用<font color=#D24D57>Nunpy</font>，不能使用tf、sklearn等***）
3. MSE损失

## 本题提交方式

> 收件邮箱：glimmer401[@outlook.com ](/outlook.com ) 
>
>主题格式：学号-姓名-考核-机器学习-03
>
>主题示例：2020091202014-张三-考核-机器学习-03


## 出题者联系方式

> QQ：1227609248
>
> 邮箱：[1227609248@qq.com](1227609248@qq.com)？
